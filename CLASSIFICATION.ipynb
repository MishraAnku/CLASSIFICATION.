{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In \\[2\\]:\n",
    "\n",
    "    #import the required libraries\n",
    "    import pandas as pd\n",
    "    from pandas import Series,DataFrame\n",
    "    #import libraries for Visualization\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline #no need to mention plt.show() each time we generate a plot\n",
    "    import numpy as np\n",
    "    import seaborn as sns\n",
    "\n",
    "    UsageError: unrecognized arguments: #no need to mention plt.show() each time we generate a plot\n",
    "\n",
    "In \\[3\\]:\n",
    "\n",
    "    #Loading the data\n",
    "    data_set = pd.read_csv(\"./iphone_purchase_records.csv\")\n",
    "\n",
    "In \\[4\\]:\n",
    "\n",
    "    X = data_set.iloc[:,:-1].values   #converting the subsetted data into an array\n",
    "    y = data_set.iloc[:,3].values\n",
    "\n",
    "In \\[5\\]:\n",
    "\n",
    "    X\n",
    "\n",
    "Out\\[5\\]:\n",
    "\n",
    "    array([['Male', 19, 19000],\n",
    "           ['Male', 35, 20000],\n",
    "           ['Female', 26, 43000],\n",
    "           ...,\n",
    "           ['Female', 50, 20000],\n",
    "           ['Male', 36, 33000],\n",
    "           ['Female', 49, 36000]], dtype=object)\n",
    "\n",
    "In \\[6\\]:\n",
    "\n",
    "    #check the data\n",
    "    data_set.head(3)\n",
    "\n",
    "Out\\[6\\]:\n",
    "\n",
    "|     | Gender | Age | Salary | Purchase Iphone |\n",
    "|-----|--------|-----|--------|-----------------|\n",
    "| 0   | Male   | 19  | 19000  | 0               |\n",
    "| 1   | Male   | 35  | 20000  | 0               |\n",
    "| 2   | Female | 26  | 43000  | 0               |\n",
    "\n",
    "In \\[7\\]:\n",
    "\n",
    "    #checking the datatypes\n",
    "    data_set.dtypes\n",
    "\n",
    "Out\\[7\\]:\n",
    "\n",
    "    Gender             object\n",
    "    Age                 int64\n",
    "    Salary              int64\n",
    "    Purchase Iphone     int64\n",
    "    dtype: object\n",
    "\n",
    "In \\[8\\]:\n",
    "\n",
    "    #Using LabelEncoder to convert Gender into a number\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    LabelEncoder_gender = LabelEncoder()\n",
    "\n",
    "In \\[9\\]:\n",
    "\n",
    "    X[:,0] = LabelEncoder_gender.fit_transform(X[:,0])  #label encoding is usually done for DV\n",
    "\n",
    "In \\[10\\]:\n",
    "\n",
    "    #Splitting the dataset\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "\n",
    "## Feature Scaling<a href=\"#Feature-Scaling\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[12\\]:\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.fit_transform(X_test)\n",
    "\n",
    "## A solver tries to find the parameter/feature weights that minimise a cost Function.<a\n",
    "href=\"#A-solver-tries-to-find-the-parameter/feature-weights-that-minimise-a-cost-Function.\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[13\\]:\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    classifier = LogisticRegression(random_state=0,solver=\"liblinear\")\n",
    "    classifier.fit(X_train,y_train)\n",
    "\n",
    "Out\\[13\\]:\n",
    "\n",
    "    LogisticRegression(random_state=0, solver='liblinear')\n",
    "\n",
    "**In a Jupyter environment, please rerun this cell to show the HTML\n",
    "representation or trust the notebook.  \n",
    "On GitHub, the HTML representation is unable to render, please try\n",
    "loading this page with nbviewer.org.**\n",
    "\n",
    "LogisticRegression\n",
    "\n",
    "    LogisticRegression(random_state=0, solver='liblinear')\n",
    "\n",
    "In \\[14\\]:\n",
    "\n",
    "    #Prediction of the DV values in the test data by our trained classifier\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "In \\[18\\]:\n",
    "\n",
    "    print(y_pred) #predictions by the model/classifier\n",
    "\n",
    "    [0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0\n",
    "     0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0\n",
    "     0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0]\n",
    "\n",
    "In \\[19\\]:\n",
    "\n",
    "    print(y_test)  #the actual DV values in the test set\n",
    "\n",
    "    [0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 0 1 0 1 0 1 0 0\n",
    "     0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0\n",
    "     1 0 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1]\n",
    "\n",
    "## Confusion Matrix<a href=\"#Confusion-Matrix\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### It can be used to find the number of correct and incorrect entries.<a\n",
    "href=\"#It-can-be-used-to-find-the-number-of-correct-and-incorrect-entries.\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "### If an individual has not purchased an iPhone and the expected value states that they have not purchased, it is a true negative (TN), i.e., the actual value is 0 and the predicted value is also 0.<a\n",
    "href=\"#If-an-individual-has-not-purchased-an-iPhone-and-the-expected-value-states-that-they-have-not-purchased,-it-is-a-true-negative-(TN),-i.e.,-the-actual-value-is-0-and-the-predicted-value-is-also-0.\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "### If an individual has not purchased an iPhone but the expected value states that they have, it is a false positive (FP), i.e., the actual value is 0 and the value expected is 1.<a\n",
    "href=\"#If-an-individual-has-not-purchased-an-iPhone-but-the-expected-value-states-that-they-have,-it-is-a-false-positive-(FP),-i.e.,-the-actual-value-is-0-and-the-value-expected-is-1.\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "### If an individual has purchased an iPhone but the expected value states that they have not, it is a false negative (FN), i.e., the real value is 1 and the value expected is 0.<a\n",
    "href=\"#If-an-individual-has-purchased-an-iPhone-but-the-expected-value-states-that-they-have-not,-it-is-a-false-negative-(FN),-i.e.,-the-real-value-is-1-and-the-value-expected-is-0.\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "### If an individual has purchased an iPhone and the expected value also says that they have purchased it is True Positive (TP), i.e., the actual value is 1 and the predicted value is also 1.<a\n",
    "href=\"#If-an-individual-has-purchased-an-iPhone-and-the-expected-value-also-says-that-they-have-purchased-it-is-True-Positive-(TP),-i.e.,-the-actual-value-is-1-and-the-predicted-value-is-also-1.\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "### Accuracy score: This is the most common metric that is used to verify model accuracy. In other words, it is the proportion of the overall number of accurate predictions to the total number of predictions.<a\n",
    "href=\"#Accuracy-score:-This-is-the-most-common-metric-that-is-used-to-verify-model-accuracy.-In-other-words,-it-is-the-proportion-of-the-overall-number-of-accurate-predictions-to-the-total-number-of-predictions.\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "### Accuracy score = (TP+TN)/(TP+TN+FP+FN)<a href=\"#Accuracy-score-=-(TP+TN)/(TP+TN+FP+FN)\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "### Recall score: It is the proportion of positive incidents that we correctly expected.<a\n",
    "href=\"#Recall-score:-It-is-the-proportion-of-positive-incidents-that-we-correctly-expected.\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "### Recall score = TP/(TP+FN)<a href=\"#Recall-score-=-TP/(TP+FN)\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### Precision score: This is the proportion of positive outcomes expected that are currently positive.<a\n",
    "href=\"#Precision-score:-This-is-the-proportion-of-positive-outcomes-expected-that-are-currently-positive.\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "### Precision score = TP/(TP+FP)<a href=\"#Precision-score-=-TP/(TP+FP)\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[21\\]:\n",
    "\n",
    "    #  - Confusion matrix\n",
    "    from sklearn import metrics\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred) \n",
    "    print(cm)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "    print(\"Accuracy score:\",accuracy)\n",
    "    precision = metrics.precision_score(y_test, y_pred) \n",
    "    print(\"Precision score:\",precision)\n",
    "    recall = metrics.recall_score(y_test, y_pred) \n",
    "    print(\"Recall score:\",recall)\n",
    "\n",
    "    [[61  2]\n",
    "     [12 25]]\n",
    "    Accuracy score: 0.86\n",
    "    Precision score: 0.9259259259259259\n",
    "    Recall score: 0.6756756756756757\n",
    "\n",
    "In \\[22\\]:\n",
    "\n",
    "     # - Feature scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X = sc.fit_transform(X)\n",
    "\n",
    "## Model Comparison<a href=\"#Model-Comparison\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### Note: Comparing the accuracy score of all the classifier models that we used above.<a\n",
    "href=\"#Note:-Comparing-the-accuracy-score-of-all-the-classifier-models-that-we-used-above.\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[24\\]:\n",
    "\n",
    "    # - Compare classification algorithms\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "In \\[26\\]:\n",
    "\n",
    "    classification_models = []\n",
    "    classification_models.append(('Logistic Regression', LogisticRegression(solver=\"liblinear\")))\n",
    "    classification_models.append(('K Nearest Neighbor', KNeighborsClassifier(n_neighbors=5,\n",
    "                                                                             metric=\"minkowski\",p=2)))\n",
    "    #minkowski appears by deafault in KNN. if p=2 then it implies we are using the euclidean distance\n",
    "    classification_models.append(('Kernel SVM', SVC(kernel = 'rbf',gamma='scale'))) #set gamma>0\n",
    "    classification_models.append(('Naive Bayes', GaussianNB()))\n",
    "    classification_models.append(('Decision Tree', DecisionTreeClassifier(criterion = \"entropy\")))\n",
    "    classification_models.append(('Random Forest', RandomForestClassifier(n_estimators=100, criterion=\n",
    "                                                                          \"entropy\")))\n",
    "\n",
    "In \\[27\\]:\n",
    "\n",
    "    for name, model in classification_models:\n",
    "      kfold = KFold(n_splits=10, random_state=(7), shuffle=(True))\n",
    "      result = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
    "      print(\"%s: Mean Accuracy = %.2f%% - SD Accuracy = %.2f%%\" % (name, result.mean()*100, \n",
    "                                                                   result.std()*100))\n",
    "\n",
    "    Logistic Regression: Mean Accuracy = 84.00% - SD Accuracy = 6.24%\n",
    "    K Nearest Neighbor: Mean Accuracy = 91.25% - SD Accuracy = 5.15%\n",
    "    Kernel SVM: Mean Accuracy = 90.75% - SD Accuracy = 4.88%\n",
    "    Naive Bayes: Mean Accuracy = 88.75% - SD Accuracy = 5.15%\n",
    "    Decision Tree: Mean Accuracy = 86.25% - SD Accuracy = 5.03%\n",
    "    Random Forest: Mean Accuracy = 89.75% - SD Accuracy = 4.39%\n",
    "\n",
    "### Recall of 1 - it shows what % of total 1 available in the data could be identified by the model.<a\n",
    "href=\"#Recall-of-1---it-shows-what-%25-of-total-1-available-in-the-data-could-be-identified-by-the-model.\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "### Precision of 1 - it shows what % of total 1 predicted by the model actually has been correctly identified.<a\n",
    "href=\"#Precision-of-1---it-shows-what-%25-of-total-1-predicted-by-the-model-actually-has-been-correctly-identified.\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "## Conclusion<a href=\"#Conclusion\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### From the results, we can see that KNN and Kernel SVM have done better than the others for this particular dataset. So, we will shortlist these two for this project. This is precisely the same result that we arrived at by independently applying each of those algorithms.<a\n",
    "href=\"#From-the-results,-we-can-see-that-KNN-and-Kernel-SVM-have-done-better-than-the-others-for-this-particular-dataset.-So,-we-will-shortlist-these-two-for-this-project.-This-is-precisely-the-same-result-that-we-arrived-at-by-independently-applying-each-of-those-algorithms.\"\n",
    "class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "     \n",
    "\n",
    "In \\[ \\]:"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
